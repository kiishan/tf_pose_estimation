{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation\n",
    "\n",
    "Environment setup\n",
    "\n",
    "[repo](https://github.com/ildoonet/tf-pose-estimation)\n",
    "\n",
    "1. create conda environment\n",
    "2. install opencv, tensorflow,protobuf, python3-tk\n",
    "3. open project dir and `pip3 install -r requirements.txt`\n",
    "4. instal swig in conda `conda install -c conda-forge/label/cf201901 swig`\n",
    "\n",
    "Ready to run\n",
    "\n",
    "\n",
    "commands to use \n",
    "\n",
    "test interface : `python run.py --model=mobilenet_thin --resize=432x368 --image=./images/p1.jpg`  \n",
    "run on webcam  : `python run_webcam.py --model=mobilenet_thin --resize=432x368 --camera=0`  \n",
    "run on video   : `python run_video.py --model=mobilenet_thin --resolution=432x368 --video=test.mp4`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on WebCam/Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_time = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    description='tf-pose-estimation realtime webcam'\n",
    "    camera= './demo_data/PullUps/v_PullUps_g08_c03.avi'\n",
    "    resize='320x240'\n",
    "    resize_out_ratio=4.0\n",
    "    model_name ='mobilenet_thin'\n",
    "    show_process=False\n",
    "    \n",
    "    model= get_graph_path(model_name)\n",
    "    w, h = model_wh(resize)\n",
    "    \n",
    "    if w > 0 and h > 0:\n",
    "        e = TfPoseEstimator(get_graph_path(model_name), target_size=(w, h))\n",
    "    else:\n",
    "        e = TfPoseEstimator(get_graph_path(model_name), target_size=(432, 368))\n",
    "        \n",
    "    cam = cv2.VideoCapture(camera)\n",
    "    ret_val, image = cam.read()\n",
    "    \n",
    "    count = 0\n",
    "    while True:\n",
    "        ret_val, image = cam.read()\n",
    "        count += 1\n",
    "        humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=resize_out_ratio)\n",
    "        \n",
    "        blank_image = np.zeros((h,w,3), np.uint8)\n",
    "        blank_image[:,:] = (255,255,255) \n",
    "        \n",
    "        original = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "        blank_image = TfPoseEstimator.draw_humans(blank_image, humans, imgcopy=False)\n",
    "        \n",
    "        cv2.imshow('blank', blank_image)\n",
    "        cv2.imshow('original', original)\n",
    "        cv2.imwrite('{}_frame_%d.jpg'.format(camera) % count, image)\n",
    "        fps_time = time.time()\n",
    "        cv2.waitKey(100)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pos_extraction(img):\n",
    "\n",
    "    image = img\n",
    "    model_name ='mobilenet_thin'\n",
    "    resize_out_ratio=4.0\n",
    "    show_process=False\n",
    "\n",
    "    model= get_graph_path(model_name)\n",
    "    w, h = image.shape[1], image.shape[0]\n",
    "\n",
    "    e = TfPoseEstimator(get_graph_path(model_name), target_size=(w, h))\n",
    "    \n",
    "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=resize_out_ratio)\n",
    "\n",
    "    blank_image = np.zeros((h,w,3), np.uint8)\n",
    "    blank_image[:,:] = (0,0,0) \n",
    "\n",
    "    image = TfPoseEstimator.draw_humans(blank_image, humans, imgcopy=False)\n",
    "    cv2.imshow('img',image)\n",
    "    cv2.waitKey(0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pos_extraction(cv2.imread('test.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './demo_data'\n",
    "image_dir= './images/'\n",
    "list_dir = os.listdir(data_dir)\n",
    "path = []\n",
    "\n",
    "for directory in list_dir:\n",
    "    path.append((directory,data_dir+'/{}'.format(directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in path:\n",
    "    globals()[category[0]] = os.listdir(category[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name ='mobilenet_thin'\n",
    "resize_out_ratio=4.0\n",
    "show_process=False\n",
    "model= get_graph_path(model_name)\n",
    "w, h = 320,240\n",
    "\n",
    "e = TfPoseEstimator(get_graph_path(model_name), target_size=(w, h))\n",
    "\n",
    "for category in path:\n",
    "    count = 0\n",
    "    if not os.path.exists(image_dir+category[0]):\n",
    "        os.makedirs(image_dir+category[0])\n",
    "    for video in globals()[category[0]]:\n",
    "        capture = cv2.VideoCapture(category[1]+'/{}'.format(video))\n",
    "        \n",
    "        fps = int(capture.get(cv2.CAP_PROP_FPS))\n",
    "        size = (int(capture.get(cv2.CAP_PROP_FRAME_WIDTH)),int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "        length = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fourcc = 0x00000021\n",
    "        \n",
    "        output_path = image_dir+category[0]+'/{}.mp4'.format(os.path.splitext(video)[0])\n",
    "        \n",
    "        writer = cv2.VideoWriter(output_path,fourcc,fps,size)\n",
    "        \n",
    "        success = True\n",
    "        \n",
    "        while success:\n",
    "            try:\n",
    "                count += 1\n",
    "                print('Read a new frame: ', success,count)\n",
    "                success,image = capture.read()\n",
    "\n",
    "                humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=resize_out_ratio)\n",
    "\n",
    "                blank_image = np.zeros((h,w,3), np.uint8)\n",
    "                blank_image[:,:] = (0,0,0)\n",
    "\n",
    "                image = TfPoseEstimator.draw_humans(blank_image, humans, imgcopy=False)\n",
    "                \n",
    "                writer.write(image)\n",
    "            except:\n",
    "                print(\"Next entry.\")\n",
    "                writer.release()\n",
    "                capture.release()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
